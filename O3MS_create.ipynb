{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import random\n",
    "import pandas as pd\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def clear_silence(audio):\n",
    "    audio_data = 0\n",
    "    dBFS = audio.dBFS\n",
    "    chunks = split_on_silence(audio,\n",
    "        min_silence_len = 150,\n",
    "        silence_thresh = dBFS-16,\n",
    "        keep_silence = 50\n",
    "    )\n",
    "    for chunk in chunks:\n",
    "        audio_data+=chunk\n",
    "    return audio_data\n",
    "\n",
    "def get_position_and_percent_Overlay(dur):\n",
    "    percent_overlay = random.randint(10, 90)\n",
    "    position = dur * percent_overlay * 0.01\n",
    "    return percent_overlay, position\n",
    "\n",
    "def get_naming(wav1, wav2, wav3, percent_overlay1, percent_overlay2):\n",
    "    ### Example input naming -> wav48/p265/p265_005.wav\n",
    "    ### Example output naming -> p265\n",
    "    name_1 = wav1.split('/')[1]\n",
    "    name_2 = wav2.split('/')[1]\n",
    "    name_3 = wav3.split('/')[1]\n",
    "    return 'spekaers-{}_{}_{}-First_percentOverlay-{}-Second_percentOverlay-{}'.format(name_1, name_2, name_3, percent_overlay1, percent_overlay2)\n",
    "\n",
    "def get_path_for_speaker(data, speaker):\n",
    "    ### Example data file ->        0                1\n",
    "    ###                     'audio_wav_path' | name_speaker\n",
    "    ### Example output list -> [path1, path2]\n",
    "    data = data[data[1] == speaker] \n",
    "    wav_path_array = data[0].unique()\n",
    "    return list(wav_path_array)\n",
    "\n",
    "def mix_audio(wav1, wav2, wav3):\n",
    "    ### Get_duration and clear silence\n",
    "    sound1 = clear_silence(AudioSegment.from_file(wav1))\n",
    "    sound2 = clear_silence(AudioSegment.from_file(wav2))\n",
    "    dur_1 = sound1.frame_count() / sound1.frame_rate * 1000\n",
    "    dur_2 = sound2.frame_count() / sound2.frame_rate * 1000\n",
    "    sound3 = clear_silence(AudioSegment.from_file(wav3))\n",
    "    dur_3 = sound3.frame_count() / sound3.frame_rate * 1000\n",
    "\n",
    "\n",
    "    ### Get position and percent overlay\n",
    "    percent_overlay_1, get_position_1 = get_position_and_percent_Overlay(dur_1)\n",
    "    percent_overlay_2, get_position_2 = get_position_and_percent_Overlay(dur_1 + dur_2 - get_position_1)\n",
    "\n",
    "    ### Create audio with final duration\n",
    "    silence = AudioSegment.silent(duration = (dur_1 + dur_2 - get_position_1) + dur_3 - get_position_2)\n",
    "\n",
    "    ### Get naming audio\n",
    "    save_name_audio = get_naming(wav1, wav2, wav3, percent_overlay_1, percent_overlay_2)\n",
    "\n",
    "    ### Save overlay audio\n",
    "    output = silence.overlay(sound1).overlay(sound2, position = dur_1 - get_position_1).overlay(sound3, dur_1 + dur_2 - get_position_1 - get_position_2)\n",
    "    output.set_frame_rate(16000).set_channels(1).export('wavs_overlay_3speakers/' + save_name_audio + '.wav', format='wav')\n",
    "    silence.overlay(sound1).set_frame_rate(16000).set_channels(1).export('spk1/' + save_name_audio + '.wav', format='wav')\n",
    "    silence.overlay(sound2, position = dur_1 - get_position_1).set_frame_rate(16000).set_channels(1).export('spk2/' + save_name_audio + '.wav', format='wav')\n",
    "    silence.overlay(sound3, dur_1 + dur_2 - get_position_1 - get_position_2).set_frame_rate(16000).set_channels(1).export('spk3/' + save_name_audio + '.wav', format='wav')\n",
    "    \n",
    "\n",
    "    ### metadata about overlay audio\n",
    "    data = {}\n",
    "    data['audioname'] = save_name_audio\n",
    "    data['first_audio_timestamp'] = [0, dur_1]\n",
    "    data['second_audio_timestamp'] = [dur_1 - get_position_1, dur_1 - get_position_1 + dur_2]\n",
    "    data['third_audio_timestamp'] = [dur_1 - get_position_1 + dur_2 - get_position_2, dur_1 - get_position_1 + dur_2 - get_position_2 + dur_3]\n",
    "    data['percent_overlay_1'] = percent_overlay_1\n",
    "    data['percent_overlay_2'] = percent_overlay_2\n",
    "    return data\n",
    "\n",
    "metadata = []\n",
    "items = list(combinations(data[1].unique(), 3))\n",
    "pool = Pool(processes=12)\n",
    "\n",
    "processes = []\n",
    "for item in tqdm(items[:50000]):\n",
    "    wavs_1st_speaker = random.choice(get_path_for_speaker(data, item[0]))\n",
    "    wavs_2nd_speaker = random.choice(get_path_for_speaker(data, item[1]))\n",
    "    wavs_3rd_speaker = random.choice(get_path_for_speaker(data, item[2]))\n",
    "    processes.append(pool.apply_async(mix_audio, (wavs_1st_speaker, wavs_2nd_speaker, wavs_3rd_speaker)))\n",
    "\n",
    "results = []\n",
    "for process in tqdm(processes):\n",
    "    results.append(process.get())\n",
    "    \n",
    "data = pd.DataFrame(data=results)\n",
    "data.to_csv('O3MS.csv', index=False, sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
